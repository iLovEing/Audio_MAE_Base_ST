{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-15T01:59:18.575048Z",
     "start_time": "2024-07-15T01:59:16.911804Z"
    }
   },
   "source": [
    "from utils import AMAEConfig\n",
    "from model import AudioMAE\n",
    "import librosa\n",
    "import os\n",
    "import torch\n",
    "from torchinfo import summary\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "test_cfg = AMAEConfig(cfg_path=r'E:\\project\\python\\Audio_MAE_Base_ST\\config\\auto_encoder.yaml')\n",
    "test_m = AudioMAE(test_cfg)\n",
    "test_f = os.path.join('datas', 'test', 'test_10s.wav')\n",
    "signal, _ = librosa.load(test_f, sr=32000, mono=True)\n",
    "model_input = torch.Tensor(signal).unsqueeze(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T01:59:12.528276Z",
     "start_time": "2024-07-15T01:59:12.505020Z"
    }
   },
   "id": "15f6bea93ad3229a",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:\\\\project\\\\python\\\\Audio_MAE_Base_ST\\\\config\\\\auto_encoder.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m test_cfg \u001B[38;5;241m=\u001B[39m \u001B[43mAMAEConfig\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcfg_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mE:\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mproject\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mpython\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mAudio_MAE_Base_ST\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mconfig\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mauto_encoder.yaml\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m test_m \u001B[38;5;241m=\u001B[39m AudioMAE(test_cfg)\n\u001B[0;32m      3\u001B[0m test_f \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdatas\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest_10s.wav\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mD:\\data\\project\\python\\Audio_MAE_Base_ST\\utils\\config.py:73\u001B[0m, in \u001B[0;36mAMAEConfig.__init__\u001B[1;34m(self, cfg_path)\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cfg_path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg_path \u001B[38;5;241m=\u001B[39m cfg_path\n\u001B[1;32m---> 73\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\data\\project\\python\\Audio_MAE_Base_ST\\utils\\config.py:93\u001B[0m, in \u001B[0;36mAMAEConfig.parse_config\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     90\u001B[0m         config[k] \u001B[38;5;241m=\u001B[39m config[k][sys_key]\n\u001B[0;32m     91\u001B[0m     config\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msys_compatible_keys\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 93\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcfg_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m     94\u001B[0m     yaml_cfg \u001B[38;5;241m=\u001B[39m yaml\u001B[38;5;241m.\u001B[39msafe_load(f)\n\u001B[0;32m     95\u001B[0m     _sys_compatible(yaml_cfg)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'E:\\\\project\\\\python\\\\Audio_MAE_Base_ST\\\\config\\\\auto_encoder.yaml'"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": "summary(test_m, input_size=(4, 320000), depth=5, col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\", \"kernel_size\"))",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T01:59:12.568102Z",
     "start_time": "2024-07-15T01:59:12.557298Z"
    }
   },
   "id": "4060e59a5347d57b",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_m' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m summary(\u001B[43mtest_m\u001B[49m, input_size\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m320000\u001B[39m), depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, col_names\u001B[38;5;241m=\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_size\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_size\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_params\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrainable\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkernel_size\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'test_m' is not defined"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "26d2800c5fcb6241"
  },
  {
   "cell_type": "code",
   "source": [
    "a = torch.tensor([2, 3, 5, 4, 1], dtype=torch.int32)\n",
    "a = a.repeat(2, 4, 1).permute(0, 2, 1)\n",
    "a.shape, a"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T02:17:15.534812Z",
     "start_time": "2024-07-15T02:17:15.531075Z"
    }
   },
   "id": "1ec8233a899376ce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5, 4]),\n",
       " tensor([[[2, 2, 2, 2],\n",
       "          [3, 3, 3, 3],\n",
       "          [5, 5, 5, 5],\n",
       "          [4, 4, 4, 4],\n",
       "          [1, 1, 1, 1]],\n",
       " \n",
       "         [[2, 2, 2, 2],\n",
       "          [3, 3, 3, 3],\n",
       "          [5, 5, 5, 5],\n",
       "          [4, 4, 4, 4],\n",
       "          [1, 1, 1, 1]]], dtype=torch.int32))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T02:20:47.777067Z",
     "start_time": "2024-07-15T02:20:47.769386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "B, L, C = a.shape\n",
    "ori_mask_token = torch.zeros(1, 1, C)\n",
    "\n",
    "len_keep = int(L * (1 - 0.6))\n",
    "noise = torch.rand(B, L, device=a.device)  # noise in [0, 1]\n",
    "\n",
    "# sort noise for each sample\n",
    "ids_shuffle = torch.argsort(noise, dim=1)  # ascend: small is keep, large is remove\n",
    "ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "\n",
    "# keep the first subset\n",
    "ids_keep = ids_shuffle[:, :len_keep]\n",
    "x_reserve = torch.gather(a, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, C))\n",
    "mask_tokens = ori_mask_token.repeat(a.shape[0], ids_restore.shape[1] - x_reserve.shape[1], 1)\n",
    "temp_x = torch.cat([x_reserve, mask_tokens], dim=1)\n",
    "x_mask = torch.gather(temp_x, dim=1, index=ids_restore.unsqueeze(-1).repeat(1, 1, a.shape[2]))\n",
    "x_mask"
   ],
   "id": "9ee8de23fe7bf199",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 2., 2., 2.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [4., 4., 4., 4.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [3., 3., 3., 3.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [4., 4., 4., 4.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T01:59:48.686061Z",
     "start_time": "2024-07-15T01:59:48.682057Z"
    }
   },
   "cell_type": "code",
   "source": "ids_shuffle",
   "id": "40c33afaa9ff200d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 0, 1, 3, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T01:59:58.389700Z",
     "start_time": "2024-07-15T01:59:58.386169Z"
    }
   },
   "cell_type": "code",
   "source": "ids_restore",
   "id": "e506eb64b3fb75ef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 4, 3, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-15T01:59:12.799972Z"
    }
   },
   "id": "ba0c90189f937d26",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "temp_df = pd.DataFrame(data=None, columns=[\"file\", \"type\", \"label\"])\n",
    "len(temp_df.index)"
   ],
   "id": "26fa1e8e9a6b51a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "temp_df.loc[len(temp_df.index)] = [os.path.join('datas', 'test', 'test_10s.wav'), 'train', -1]\n",
    "temp_df.loc[len(temp_df.index)] = [os.path.join('datas', 'test', 'test_30s.wav'), 'eval', -1]"
   ],
   "id": "a64777b25f8cb5c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "temp_df.reset_index(drop=True, inplace=True)\n",
    "temp_df"
   ],
   "id": "9a76722a9f3ebbf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "temp_df.to_csv(os.path.join('workspace', 'test.csv'))",
   "id": "7b09f169c0670248",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "rdf = pd.read_csv(os.path.join('workspace', 'test.csv'), index_col=0)",
   "id": "8ff3fe84189e8911",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "rdf",
   "id": "239e3fe688034e02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "list(rdf['file'])",
   "id": "d7c5022a68bee039",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "list(rdf[rdf['type'] == 'train']['file'])",
   "id": "5ad17ec147a3cc76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "a = 'aabccd.hdf5'\n",
    "a"
   ],
   "id": "d9e5ca565ef241ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "str_list = list(a)\n",
    "str_list"
   ],
   "id": "7ff44844a5676efc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n = 5\n",
    "str_list.insert(-5, f'_{n}')\n",
    "str_list"
   ],
   "id": "1bb3749eae35bb51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_hdf5_handler(base_name):\n",
    "    suffix = base_name.split('.')[-1]\n",
    "    prefix = base_name[:-len(suffix) - 1]\n",
    "    hdf5_files = [prefix + f'_{i}.' + suffix for i in range(2)]\n",
    "    h5f_l = []\n",
    "    return h5f_l\n",
    "\n",
    "result = get_hdf5_handler('test.hdf5')\n",
    "result"
   ],
   "id": "5182f9ce5638704d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result = get_hdf5_handler('test.hdf5')\n",
    "result"
   ],
   "id": "757149f597385163",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ll = [round(i * 119 / 10) for i in range(1, 1+10)]\n",
    "ll"
   ],
   "id": "cbf72ead3ad14af8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import bisect\n",
    "bisect.bisect_left(ll, 119)"
   ],
   "id": "44da532c49a76290",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import torchaudio\n",
    "test_f = os.path.join('datas', 'test', 'test_5s.wav')"
   ],
   "id": "5b1214b01f2c449c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "signal, sr = torchaudio.load(test_f)\n",
    "signal_tensor = torchaudio.functional.resample(signal, sr, 32000)\n",
    "signal_tensor = signal_tensor[:, :16000]\n",
    "signal_tensor.mean()"
   ],
   "id": "78fb9d42ddacac0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fbank1 = torchaudio.compliance.kaldi.fbank(signal_tensor, sample_frequency=32000, num_mel_bins=64, frame_length=25, frame_shift=10, use_energy=False, htk_compat=True, window_type='hanning')\n",
    "fbank1.shape, fbank1"
   ],
   "id": "9241e4170c98aba8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fbank2_m = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=32000,\n",
    "    n_fft = 800,\n",
    "    hop_length = 320,\n",
    "    f_min = 20.0,\n",
    "    n_mels = 64,\n",
    ")\n",
    "fbank2 = fbank2_m(signal_tensor)\n",
    "log_offset = 1e-6\n",
    "fbank2 = torch.log(fbank2 + log_offset).permute(0, 2, 1).squeeze(0)\n",
    "fbank2.shape, fbank2"
   ],
   "id": "8e7946036ae90a45",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "spe_m = Spectrogram(n_fft=800, hop_length=320, win_length=800)\n",
    "fbank3_m = LogmelFilterBank(sr=32000, n_fft=800, n_mels=64, fmin=20., top_db=None)\n",
    "fbank3 = spe_m(signal_tensor)\n",
    "fbank3 = fbank3_m(fbank3).squeeze(0).squeeze(0)\n",
    "fbank3.shape, fbank3"
   ],
   "id": "44297a7200762af8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "def _pre_process(waveform):\n",
    "    waveform = waveform - waveform.mean()\n",
    "    idx = np.random.randint(len(waveform))\n",
    "    rolled_waveform = np.roll(waveform, idx)\n",
    "    mag = np.random.beta(10, 10) + 0.5\n",
    "    waveform = rolled_waveform * mag\n",
    "\n",
    "    return torch.Tensor(waveform)"
   ],
   "id": "c19f7a929a2d8492",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "waveform, _ = librosa.load(test_f, sr=32000)\n",
    "# waveform = _pre_process(waveform)\n",
    "type(waveform), waveform.shape"
   ],
   "id": "e4fca8eb867afcba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from utils import AMAEConfig\n",
    "cfg = AMAEConfig(cfg_path='config/pretrain.yaml')"
   ],
   "id": "6927340cadf1a831",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(cfg)",
   "id": "4eaae3ae29c95391",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "67dbb7d5535816f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import torch",
   "id": "1930a612db6c6dd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "a = torch.tensor(list(range(12)), dtype=torch.int32)\n",
    "a"
   ],
   "id": "bbba815a52bf1cef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "a = a.reshape(3, 4)\n",
    "a"
   ],
   "id": "5fc41a9e375640af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "a.permute(1, 0)",
   "id": "a28e6bc1c61bde51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def random_mask(self, x):\n",
    "    B, C, T, F = x.shape\n",
    "    L = T * F\n",
    "    x = x.reshape(B, C, -1)\n",
    "\n",
    "    len_keep = int(L * (1 - self.mask_ratio))\n",
    "    noise = torch.rand(B, C, L, device=x.device)  # noise in [0, 1]\n",
    "    ids_shuffle = torch.argsort(noise, dim=2)  # ascend: small is keep, large is remove\n",
    "    ids_restore = torch.argsort(ids_shuffle, dim=2)\n",
    "\n",
    "    keep_mask = torch.zeros([B, C, L], device=x.device)\n",
    "    keep_mask[:, :, :len_keep] = 1\n",
    "    keep_mask = torch.gather(keep_mask, dim=2, index=ids_restore)\n",
    "    x_masked = torch.mul(x, keep_mask)\n",
    "\n",
    "    remove_mask = torch.ones([B, C, L], device=x.device)\n",
    "    if self.restore_mask_only:\n",
    "        remove_mask[:, :, :len_keep] = 0\n",
    "        remove_mask = torch.gather(remove_mask, dim=2, index=ids_restore)\n",
    "\n",
    "    return x_masked.reshape(B, C, T, F), remove_mask.reshape(B, C, T, F)"
   ],
   "id": "3860f6f538827ead",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
